from dataclasses import dataclass
from datetime import date, datetime, timedelta, time
import pandas as pd
import numpy as np
import logging
import json
from typing import List, Dict, Optional
from scipy.stats import linregress
import os
import time as time_module  # rename time to avoid conflict
# library pra interagir com formato Parquet
import pyarrow as pa
import pyarrow.parquet as pq
# Library Binance
from binance.client import Client

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


## Section to execute binance related and data retrival commands:

class BinanceTrader():
    def __init__(self, file_path=None, api_key=None, api_secret=None):
        if file_path:
            try:
                with open(file_path) as f:
                    envBinance = json.load(f)
                self.api_key  = envBinance['APIKey']
                self.api_secret = envBinance['SecretKey']
            except: print("Erro ao ler as credenciais"); quit()
        else:
            self.api_key  = envBinance['APIKey']
            self.api_secret = envBinance['SecretKey']
            if (api_key and api_secret ) == None: 
                print("Erro ao ler as credenciais")
                quit()
        # Setting connection
        self.client = Client(api_key,api_secret) 
        # Getting server status. Empty means no errors.
        status = self.client.ping()
        if not status:
            # The JSON response is empty meaning no errors. 
            print("Connection successful.")
        else: 
            print(status)
            quit()
            
        # inicializando variaveis necessarias para as funções
        self.timeframe_dict = {                         
            'M1': [self.client.KLINE_INTERVAL_1MINUTE, 60],  # 1 minute # takes an average of 35 min to update starting from 2017.
            'M3': [self.client.KLINE_INTERVAL_3MINUTE, 180],  # 3 minutes
            'M5': [self.client.KLINE_INTERVAL_5MINUTE, 300],  # 5 minutes
            'M15': [self.client.KLINE_INTERVAL_15MINUTE, 900],  # 15 minutes
            'M30': [self.client.KLINE_INTERVAL_30MINUTE, 1800],  # 30 minutes
            'H1': [self.client.KLINE_INTERVAL_1HOUR, 3600],  # 1 hour
            'H2': [self.client.KLINE_INTERVAL_2HOUR, 7200],  # 2 hours
            'H4': [self.client.KLINE_INTERVAL_4HOUR, 14400],  # 4 hours
            'H6': [self.client.KLINE_INTERVAL_6HOUR, 21600],  # 6 hours
            'H8': [self.client.KLINE_INTERVAL_8HOUR, 28800],  # 8 hours
            'H12': [self.client.KLINE_INTERVAL_12HOUR, 43200],  # 12 hours
            'D1': [self.client.KLINE_INTERVAL_1DAY, 86400],  # 1 day
            'D3': [self.client.KLINE_INTERVAL_3DAY, 259200],  # 3 day
            'W1': [self.client.KLINE_INTERVAL_1WEEK, 604800],  # 1 week
            'MN1': [self.client.KLINE_INTERVAL_1MONTH, 2592000],  # 1 month
        }
        
        # Se nao tivermos as pastas (primeira inicialização), devemos cria-las
        if not os.path.isdir('binancedata\\ohlc'):
                os.mkdir('binancedata')
                os.mkdir('binancedata\\ohlc')
                print("Creating timeframe folders.")
                for timeframe_dir in self.timeframe_dict.keys():
                    try: 
                        os.mkdir(f'binancedata\\ohlc\\{timeframe_dir}')
                        print(f'binancedata\\ohlc\\{timeframe_dir} created.')
                    except FileExistsError: 
                        print(FileExistsError)
                        pass
        elif not os.path.isdir('binancedata\\ohlc'): 
            os.mkdir('binancedata\\ohlc')

##############################################################binance_update_ohlc###########################################################

    # FUNCTIONS ================================================   
    def binance_update_ohlc(self, symbol, timeframe, verbose=False):
        start_time = int(pd.Timestamp(datetime(2012, 1, 1), tz='UTC').timestamp() * 1000)
        end_time = int(pd.Timestamp(datetime.now(), tz='UTC').timestamp() * 1000)
        klines_columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_volume', 'taker_buy_quote_volume', 'ignore']
        print("Dados de tempo e colunas iniciadas. Iniciando funcao binance_update_ohlc.")
        
        # Checar se o ativo ja tem a file necessária
        if not os.path.exists(f'binancedata\\ohlc\\{timeframe}\\{symbol}_{timeframe}.parquet'): 
            print("Arquivo ainda nao existe. Iniciando o dataframe.")
            df = pd.DataFrame(columns=klines_columns)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
        # Se a file ja existe, checar a data e repor a data inicial de pesquisa    
        else: 
            print("Arquivo ja existe. Lendo o arquivo parquet e iniciando o dataframe.")
            df = pq.ParquetFile(f'binancedata\\ohlc\\{timeframe}\\{symbol}_{timeframe}.parquet').read().to_pandas()
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            if df['timestamp'].max() < datetime.now() - timedelta(seconds=self.timeframe_dict[timeframe][1]):
                start_time = int(pd.Timestamp(df['timestamp'].max(), tz='UTC').timestamp() * 1000)
                print("Diferenca do ultimo registro pra hoje e anterior ao timeframe declarado. Atualizando a partir do ultimo registro")
            else: 
                print("Diferenca do ultimo registro pra hoje menor que timeframe declarado. Sem updates.")
                return
                
        # Definindo timeframes        
        timeframe_name = timeframe
        interval = self.timeframe_dict[timeframe][0]

    
        all_klines = []
        
        while start_time < end_time:
            if verbose: print(f" Getting the first 1000 after the start_time: {pd.to_datetime(start_time, unit='ms', utc=True)}.")
            klines = self.client.get_klines(symbol=symbol, interval=interval, startTime=start_time)
            
            if not klines:
                print(f"No data for start time: {pd.to_datetime(start_time, unit='ms', utc=True)}.")
                break
            
            all_klines.extend(klines)
            start_time = klines[-1][6]  # Use the last close_time for pagination
            if verbose: print(f" New start_time: {pd.to_datetime(start_time, unit='ms', utc=True)}.")
        
        # Convert to DataFrame
        
        df_aux = pd.DataFrame(all_klines, columns=klines_columns)
        df_aux['timestamp'] = pd.to_datetime(df_aux['timestamp'], unit='ms')
        print(f"Total de linhas importadas: {len(df_aux)}")

        # Appending data to dataframe
        print('Concatenando dados.')
        df = pd.concat([df_aux, df], ignore_index=True)
        # Fixing format
        df.sort_values(by='timestamp', ascending=True, inplace=True)
        df = df.drop_duplicates(subset=['timestamp'])
        df[['open', 'high','low', 'close','volume', 'quote_asset_volume','taker_buy_base_volume', 'taker_buy_quote_volume']] = df[['open', 'high','low', 'close','volume', 'quote_asset_volume','taker_buy_base_volume', 'taker_buy_quote_volume']].astype(float)
        # Save df to file
        filename = f'binancedata\\ohlc\\{timeframe_name}\\{symbol}_{timeframe_name}.parquet'
        print(f'Salvando arquivo final em {filename}. \n')
        table = pa.Table.from_pandas(df)
        with pq.ParquetWriter(filename, table.schema) as writer:
            writer.write_table(table)

################################################slice###############################################################################

    def slice(self, type, symbol, initial_date, final_date, timeframe=None):
        path = f'binancedata\\ohlc\\{timeframe}\\{symbol}_{timeframe}.parquet' #if type=='ohlc' else f'ticks\\{symbol}_ticksrange.parquet'
        if not os.path.exists(path):
            print(f"O ativo {symbol} não está registrado, favor criá-lo utilizando a função .update_{type}()")
        else:
            df = pq.ParquetFile(path).read().to_pandas()
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df.set_index('timestamp', inplace=True)
            df[['open', 'high','low', 'close','volume', 'quote_asset_volume','taker_buy_base_volume', 'taker_buy_quote_volume']] = df[['open', 'high','low', 'close','volume', 'quote_asset_volume','taker_buy_base_volume', 'taker_buy_quote_volume']].astype(float)
            return df.loc[(df.index >= initial_date) & (df.index < final_date)]
        pass
        
#################################################read_ohlc##############################################################################    
    
    def read_ohlc(self, symbol, timeframe, initial_date=datetime(2012, 1, 1), final_date=datetime.now()):
        return self.slice('ohlc', symbol, initial_date, final_date, timeframe)

#    def read_ticks(self, symbol, initial_date=datetime(2012, 1, 1), final_date=datetime.now()):
#        return self.slice('ticks', symbol, initial_date, final_date)
#
    def update_ohlc_alltimeframes(self, symbol):
        results = {}  # To store results for each timeframe
        for timeframe_key in reversed(list(self.timeframe_dict.keys())):
            try:
                print(f'Updating values for symbol: {symbol} and timeframe: {timeframe_key}.')
                # Call the update function and store the result
                results[timeframe_key] = self.binance_update_ohlc(symbol, timeframe_key)
            except Exception as iterationError:
                print(f"Error updating {timeframe_key}: {iterationError}")
                results[timeframe_key] = None  # Optionally record the error
                pass
        return print('Timeframe iterations completed.')


## Section to execute the trading strategy

@dataclass
class TradeConfig:
    initial_capital: float = 2000
    leverage: float = 5
    base_bet_size: float = 10
    rsi_period: int = 14
    rsi_ma_period: int = 14
    stop_loss_pct: float = 2.0
    take_profit_pct: float = 4.0
    risk_per_trade_pct: float = 1.0
    volatility_lookback: int = 20
    trend_lookback: int = 50
    min_volatility_threshold: float = 0.5
    max_volatility_threshold: float = 3.0
    position_scaling: bool = True


class TradingStrategy:
    def __init__(self, config: TradeConfig):
        self.config = config
        self.current_capital = config.initial_capital
        self.trades_history: List[Dict] = []
        self.current_drawdown = 0
        self.peak_capital = config.initial_capital

    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """Calculate advanced technical indicators for trading decisions."""
        df = df.copy()
        
        # Volatility indicators
        df['atr'] = self.calculate_atr(df, period=14)
        df['volatility'] = df['close'].pct_change().rolling(window=self.config.volatility_lookback).std()
        
        # Trend indicators
        df['ema_20'] = df['close'].ewm(span=20, adjust=False).mean()
        df['ema_50'] = df['close'].ewm(span=50, adjust=False).mean()
        df['trend_strength'] = (df['ema_20'] - df['ema_50']) / df['ema_50'] * 100
        
        # Calculate RSI divergence
        df['rsi_slope'] = self.calculate_slope(df['RSI'], period=10)
        df['price_slope'] = self.calculate_slope(df['close'], period=10)
        df['divergence'] = np.where((df['rsi_slope'] < 0) & (df['price_slope'] > 0), -1,
                                  np.where((df['rsi_slope'] > 0) & (df['price_slope'] < 0), 1, 0))
        
        return df


    @staticmethod
    def calculate_atr(df: pd.DataFrame, period: int = 14) -> pd.Series:
        """Calculate Average True Range."""
        high = df['high']
        low = df['low']
        close = df['close']
        
        tr1 = high - low
        tr2 = abs(high - close.shift())
        tr3 = abs(low - close.shift())
        
        tr = pd.DataFrame({'tr1': tr1, 'tr2': tr2, 'tr3': tr3}).max(axis=1)
        atr = tr.ewm(span=period, adjust=False).mean()  # Use exponential moving average for more recent bias
        return atr

    @staticmethod
    def calculate_slope(series: pd.Series, period: int = 10) -> pd.Series:
        """Calculate the slope of a series using linear regression."""
        slopes = series.rolling(window=period).apply(lambda x: linregress(np.arange(period), x)[0], raw=True)
        return slopes

    def calculate_position_size(self, price: float, volatility: float) -> float:
        """Dynamic position sizing based on volatility and account risk."""
        risk_amount = self.current_capital * (self.config.risk_per_trade_pct / 100)
        
        # Adjust position size based on volatility
        volatility_scalar = 1.0
        if self.config.position_scaling:
            volatility_scalar = max(0.5, min(1.5, 1 / volatility))
        
        position_size = (risk_amount * volatility_scalar) / (self.config.stop_loss_pct / 100) * self.config.leverage
        return min(position_size, self.current_capital * 0.5)  # Max 50% of capital per trade

    def process_month(self, df: pd.DataFrame) -> dict:
        """Process monthly data with enhanced strategy logic."""
        if df.empty:
            logging.warning("Empty dataframe received for processing.")
            return self.create_empty_metrics()

        df = self.calculate_technical_indicators(df)
        position = 0
        entry_price = 0
        monthly_trades = []

        for i in range(1, len(df)):
            current_row = df.iloc[i]
            prev_row = df.iloc[i-1]
            
            if position != 0:
                price_change_pct = (current_row['close'] - entry_price) / entry_price * 100
                exit_trades = self.check_exit_conditions(
                    monthly_trades, current_row, prev_row, price_change_pct, position
                )
                if exit_trades:
                    monthly_trades.extend(exit_trades)
                    position = 0

            if position == 0:
                entry_signal = self.check_entry_conditions(current_row, prev_row)
                if entry_signal:
                    position_size = self.calculate_position_size(
                        current_row['close'], current_row['volatility']
                    )
                    entry_trade = {
                        'timestamp': current_row.name,
                        'price': current_row['close'],
                        'quantity': position_size,
                        'type': 'buy',
                        'indicators': {
                            'rsi': current_row['RSI'],
                            'trend_strength': current_row['trend_strength'],
                            'volatility': current_row['volatility']
                        }
                    }
                    monthly_trades.append(entry_trade)
                    position = position_size
                    entry_price = current_row['close']

        return self.calculate_monthly_metrics(monthly_trades)

    def check_entry_conditions(
            self, row: pd.Series, prev_row: pd.Series
    ) -> bool:
        """Enhanced entry conditions with multiple confirmations."""
        # Get the volume series from the original DataFrame
        volume_ma = self.volume_series.rolling(20).mean()
        current_volume = row['volume']
    
        # Basic RSI conditions
        rsi_signal = (row['RSI'] > row['RSI_MA'] and prev_row['RSI'] <= prev_row['RSI_MA'])
    
        # Trend confirmation
        trend_signal = row['trend_strength'] > 0
    
        # Volatility filter
        volatility_ok = (
                row['volatility'] >= self.config.min_volatility_threshold and
                row['volatility'] <= self.config.max_volatility_threshold
        )
        
        # Volume confirmation using the current index
        volume_signal = current_volume > volume_ma.loc[row.name]
    
        return (rsi_signal and trend_signal and volatility_ok and volume_signal)   
        
    def check_exit_conditions(
        self, trades: List[Dict], row: pd.Series, prev_row: pd.Series, 
        price_change_pct: float, position: float
        ) -> List[Dict]:
        """Enhanced exit conditions with trailing stops and multiple signals."""
        exit_trades = []
        
        # Dynamic stop loss based on ATR
        dynamic_stop = self.config.stop_loss_pct * (1 + row['atr'] / row['close'])
        
        # Exit conditions
        stop_loss_hit = price_change_pct <= -dynamic_stop
        trend_reversal = (row['trend_strength'] < 0 and prev_row['trend_strength'] > 0)
        rsi_reversal = (row['RSI'] < row['RSI_MA'] and prev_row['RSI'] > prev_row['RSI_MA'])
        
        if stop_loss_hit or trend_reversal or rsi_reversal:
            exit_trades.append({
                'timestamp': row.name,
                'price': row['close'],
                'quantity': -position,
                'type': 'stop_loss' if stop_loss_hit else 'sell',
                'reason': 'stop_loss' if stop_loss_hit else 'signal_reversal'
            })
            
        return exit_trades

    def calculate_monthly_metrics(self, trades: List[Dict]) -> dict:
        """Calculate comprehensive trading metrics."""
        if not trades:
            return self.create_empty_metrics()

        df_trades = pd.DataFrame(trades)
        df_trades['pnl'] = pd.Series(dtype=float)  # Initialize empty pnl column
        
        # Calculate PnL for each trade
        for i in range(1, len(df_trades)):
            if df_trades.iloc[i]['type'] in ['sell', 'stop_loss']:
                entry_price = df_trades.iloc[i-1]['price']
                exit_price = df_trades.iloc[i]['price']
                quantity = abs(df_trades.iloc[i]['quantity'])
                df_trades.iloc[i, df_trades.columns.get_loc('pnl')] = (
                    (exit_price - entry_price) * quantity
                )

        total_pnl = df_trades['pnl'].sum()
        num_trades = len(df_trades[df_trades['type'].isin(['sell', 'stop_loss'])])
        winning_trades = len(df_trades[df_trades['pnl'] > 0])
        
        # Update capital and track drawdown
        self.current_capital += total_pnl
        self.peak_capital = max(self.peak_capital, self.current_capital)
        self.current_drawdown = (self.peak_capital - self.current_capital) / self.peak_capital * 100

        metrics = {
            'return': total_pnl,
            'trades': num_trades,
            'win_rate': (winning_trades / num_trades * 100) if num_trades > 0 else 0,
            'avg_trade_return': total_pnl / num_trades if num_trades > 0 else 0,
            'sharpe_ratio': self.calculate_sharpe_ratio(df_trades),
            'max_drawdown': self.current_drawdown,
            'current_capital': self.current_capital
        }
        
        return metrics

    def create_empty_metrics(self) -> dict:
        """Create empty metrics dictionary."""
        return {
            'return': 0,
            'trades': 0,
            'win_rate': 0,
            'avg_trade_return': 0,
            'sharpe_ratio': 0,
            'max_drawdown': 0,
            'current_capital': self.current_capital
        }

    def calculate_sharpe_ratio(self, df_trades: pd.DataFrame) -> float:
        """Calculate Sharpe ratio from trade data."""
        if df_trades.empty or 'pnl' not in df_trades.columns:
            return 0
            
        daily_returns = df_trades.set_index('timestamp')['pnl'].resample('D').sum()
        if len(daily_returns) < 2:
            return 0
            
        return np.sqrt(252) * daily_returns.mean() / daily_returns.std() if daily_returns.std() != 0 else 0